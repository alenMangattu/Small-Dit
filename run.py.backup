

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os
import math
import json
from tqdm import tqdm
import random

# Assuming model.py contains the DiT and DiTConfig classes
from model import DiT, DiTConfig

# --- 1. DATA HANDLING ---

class DummyImageDataset(Dataset):
    """
    A dummy dataset that generates random solid-color images and assigns them a class label.
    This is used as a fallback to ensure the training script can run without a real dataset.
    """
    def __init__(self, num_samples=10000, image_size=256, num_classes=10):
        self.num_samples = num_samples
        self.image_size = image_size
        self.num_classes = num_classes
        self.transform = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1]
        ])

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # Generate a random color
        random_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
        img = Image.new('RGB', (self.image_size, self.image_size), color=random_color)
        
        # Assign a random class label
        label = torch.randint(0, self.num_classes, (1,)).item()
        
        return self.transform(img), label

# --- 2. DIFFUSION UTILITIES ---

def get_beta_schedule(num_diffusion_timesteps):
    """
    Returns a linear beta schedule.
    """
    betas = torch.linspace(0.0001, 0.02, num_diffusion_timesteps)
    return betas

def q_sample(x_start, t, alphas_cumprod, noise=None):
    """
    Forward diffusion process: add noise to an image.
    """
    if noise is None:
        noise = torch.randn_like(x_start)
    
    sqrt_alphas_cumprod_t = torch.sqrt(alphas_cumprod[t])[:, None, None, None]
    sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1.0 - alphas_cumprod[t])[:, None, None, None]
    
    noisy_image = sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise
    return noisy_image

# --- 3. SAMPLING (Reverse Process) ---

@torch.no_grad()
def p_sample_loop(model, shape, num_timesteps, alphas, betas, alphas_cumprod, device, class_label=0):
    """
    Reverse diffusion process: generate an image from noise.
    """
    img = torch.randn(shape, device=device)
    
    # Create a fixed class label tensor for the batch
    labels = torch.tensor([class_label] * shape[0], device=device)

    for i in tqdm(reversed(range(num_timesteps)), desc="Sampling", total=num_timesteps, leave=False):
        t = torch.full((shape[0],), i, device=device, dtype=torch.long)
        
        predicted_noise = model(img, t, labels)
        
        alpha_t = alphas[t][:, None, None, None]
        alpha_cumprod_t = alphas_cumprod[t][:, None, None, None]
        beta_t = betas[t][:, None, None, None]
        
        # DDPM sampling step
        if i > 0:
            noise = torch.randn_like(img)
        else:
            noise = torch.zeros_like(img)
            
        img = 1 / torch.sqrt(alpha_t) * (img - ((1 - alpha_t) / torch.sqrt(1 - alpha_cumprod_t)) * predicted_noise) + torch.sqrt(beta_t) * noise
        
    return img

def save_sample_image(tensor, path):
    """
    Save a tensor as an image.
    """
    # Denormalize from [-1, 1] to [0, 1]
    tensor = (tensor + 1) / 2
    tensor.clamp_(0, 1)
    
    # Convert to PIL image and save
    img = transforms.ToPILImage()(tensor)
    img.save(path)

# --- 4. TRAINING SCRIPT ---

def main():
    # --- Config ---
    config = DiTConfig(
        image_size=64,      # Use smaller images for faster training on dummy data
        patch_size=8,
        in_channels=3,
        n_embd=512,
        n_head=8,
        n_layer=6,
        dropout=0.1
    )
    
    # Training Hyperparameters
    epochs = 100
    batch_size = 32
    learning_rate = 1e-4
    num_classes = 10 # As defined in DummyImageDataset
    num_diffusion_timesteps = 1000
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Create output directory for samples
    os.makedirs("samples", exist_ok=True)

    # --- Dataset and DataLoader ---
    print("Loading dummy dataset...")
    dataset = DummyImageDataset(num_samples=5000, image_size=config.image_size, num_classes=num_classes)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    
    # --- Model, Optimizer, Loss ---
    print(f"Initializing DiT model on {device}...")
    model = DiT(config, num_classes=num_classes)
    
    print("Compiling model with torch.compile()...")
    model = torch.compile(model)

    if torch.cuda.device_count() > 1:
        print(f"Using {torch.cuda.device_count()} GPUs with DataParallel.")
        model = nn.DataParallel(model)
        
    model.to(device)
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
    criterion = nn.MSELoss()

    # --- Diffusion Schedule ---
    betas = get_beta_schedule(num_diffusion_timesteps).to(device)
    alphas = 1. - betas
    alphas_cumprod = torch.cumprod(alphas, dim=0)

    # --- Training Loop ---
    print("Starting training...")
    step = 0
    for epoch in range(epochs):
        progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
        for i, (images, labels) in enumerate(progress_bar):
            images = images.to(device)
            labels = labels.to(device)
            
            # 1. Sample a random timestep for each image in the batch
            t = torch.randint(0, num_diffusion_timesteps, (images.shape[0],), device=device).long()
            
            # 2. Generate noise and create noisy images (forward process)
            noise = torch.randn_like(images)
            noisy_images = q_sample(images, t, alphas_cumprod, noise)
            
            # 3. Get model prediction
            optimizer.zero_grad()
            predicted_noise = model(noisy_images, t, labels)
            
            # 4. Calculate loss
            loss = criterion(predicted_noise, noise)
            
            # 5. Backpropagate and update weights
            loss.backward()
            optimizer.step()
            
            progress_bar.set_postfix(loss=loss.item())
            step += 1

            # --- Generate and save a sample image ---
            if step % 100 == 0:
                print(f"\nStep {step}: Generating sample image...")
                model.eval() # Set model to evaluation mode
                
                # Generate a sample for a fixed class (e.g., class 2)
                sample_shape = (1, config.in_channels, config.image_size, config.image_size)
                sample = p_sample_loop(model, sample_shape, num_diffusion_timesteps, alphas, betas, alphas_cumprod, device, class_label=2)
                
                save_path = f"samples/sample_step_{step}_class_2.png"
                save_sample_image(sample[0].cpu(), save_path)
                print(f"Saved sample to {save_path}")
                
                model.train() # Set model back to training mode

    print("Training finished.")

if __name__ == "__main__":
    main()
